---- Relu Matches (246 in 16 files) ----
Cudnn_relu_layer.cpp (src\caffe\layers):#include "caffe/layers/cudnn_relu_layer.hpp"
Cudnn_relu_layer.cpp (src\caffe\layers):void CuDNNReLULayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
Cudnn_relu_layer.cpp (src\caffe\layers):  ReLULayer<Dtype>::LayerSetUp(bottom, top);
Cudnn_relu_layer.cpp (src\caffe\layers):void CuDNNReLULayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
Cudnn_relu_layer.cpp (src\caffe\layers):  ReLULayer<Dtype>::Reshape(bottom, top);
Cudnn_relu_layer.cpp (src\caffe\layers):CuDNNReLULayer<Dtype>::~CuDNNReLULayer() {
Cudnn_relu_layer.cpp (src\caffe\layers):INSTANTIATE_CLASS(CuDNNReLULayer);
Cudnn_relu_layer.hpp (include\caffe\layers):#ifndef CAFFE_CUDNN_RELU_LAYER_HPP_
Cudnn_relu_layer.hpp (include\caffe\layers):#define CAFFE_CUDNN_RELU_LAYER_HPP_
Cudnn_relu_layer.hpp (include\caffe\layers):#include "caffe/layers/relu_layer.hpp"
Cudnn_relu_layer.hpp (include\caffe\layers): * @brief CuDNN acceleration of ReLULayer.
Cudnn_relu_layer.hpp (include\caffe\layers):class CuDNNReLULayer : public ReLULayer<Dtype> {
Cudnn_relu_layer.hpp (include\caffe\layers):  explicit CuDNNReLULayer(const LayerParameter& param)
Cudnn_relu_layer.hpp (include\caffe\layers):      : ReLULayer<Dtype>(param), handles_setup_(false) {}
Cudnn_relu_layer.hpp (include\caffe\layers):  virtual ~CuDNNReLULayer();
Cudnn_relu_layer.hpp (include\caffe\layers):#endif  // CAFFE_CUDNN_RELU_LAYER_HPP_
Filler.hpp (include\caffe): * accounts for ReLU nonlinearities.
Layer_factory.cpp (src\caffe):#include "caffe/layers/relu_layer.hpp"
Layer_factory.cpp (src\caffe):#include "caffe/layers/cudnn_relu_layer.hpp"
Layer_factory.cpp (src\caffe):// ×¢²áReLU²ã  
Layer_factory.cpp (src\caffe):// Get relu layer according to engine.
Layer_factory.cpp (src\caffe):shared_ptr<Layer<Dtype> > GetReLULayer(const LayerParameter& param) {
Layer_factory.cpp (src\caffe):  ReLUParameter_Engine engine = param.relu_param().engine();
Layer_factory.cpp (src\caffe):  if (engine == ReLUParameter_Engine_DEFAULT) {
Layer_factory.cpp (src\caffe):    engine = ReLUParameter_Engine_CAFFE;
Layer_factory.cpp (src\caffe):    engine = ReLUParameter_Engine_CUDNN;
Layer_factory.cpp (src\caffe):  if (engine == ReLUParameter_Engine_CAFFE) {
Layer_factory.cpp (src\caffe):    return shared_ptr<Layer<Dtype> >(new ReLULayer<Dtype>(param));
Layer_factory.cpp (src\caffe):  } else if (engine == ReLUParameter_Engine_CUDNN) {
Layer_factory.cpp (src\caffe):    return shared_ptr<Layer<Dtype> >(new CuDNNReLULayer<Dtype>(param));
Layer_factory.cpp (src\caffe):REGISTER_LAYER_CREATOR(ReLU, GetReLULayer);
Prelu_layer.cpp (src\caffe\layers):#include "caffe/layers/prelu_layer.hpp"
Prelu_layer.cpp (src\caffe\layers):void PReLULayer<Dtype>::LayerSetUp(const vector<Blob<Dtype>*>& bottom,
Prelu_layer.cpp (src\caffe\layers):  PReLUParameter prelu_param = this->layer_param().prelu_param();
Prelu_layer.cpp (src\caffe\layers):  channel_shared_ = prelu_param.channel_shared();
Prelu_layer.cpp (src\caffe\layers):    if (prelu_param.has_filler()) {
Prelu_layer.cpp (src\caffe\layers):      filler.reset(GetFiller<Dtype>(prelu_param.filler()));
Prelu_layer.cpp (src\caffe\layers):void PReLULayer<Dtype>::Reshape(const vector<Blob<Dtype>*>& bottom,
Prelu_layer.cpp (src\caffe\layers):void PReLULayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
Prelu_layer.cpp (src\caffe\layers):void PReLULayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
Prelu_layer.cpp (src\caffe\layers):STUB_GPU(PReLULayer);
Prelu_layer.cpp (src\caffe\layers):INSTANTIATE_CLASS(PReLULayer);
Prelu_layer.cpp (src\caffe\layers):REGISTER_LAYER_CLASS(PReLU);
Prelu_layer.hpp (include\caffe\layers):#ifndef CAFFE_PRELU_LAYER_HPP_
Prelu_layer.hpp (include\caffe\layers):#define CAFFE_PRELU_LAYER_HPP_
Prelu_layer.hpp (include\caffe\layers): *        @f$. The differences from ReLULayer are 1) negative slopes are
Prelu_layer.hpp (include\caffe\layers):class PReLULayer : public NeuronLayer<Dtype> {
Prelu_layer.hpp (include\caffe\layers):   * @param param provides PReLUParameter prelu_param,
Prelu_layer.hpp (include\caffe\layers):   *     with PReLULayer options:
Prelu_layer.hpp (include\caffe\layers):  explicit PReLULayer(const LayerParameter& param)
Prelu_layer.hpp (include\caffe\layers):  virtual inline const char* type() const { return "PReLU"; }
Prelu_layer.hpp (include\caffe\layers):   * @brief Computes the error gradient w.r.t. the PReLU inputs.
Prelu_layer.hpp (include\caffe\layers):#endif  // CAFFE_PRELU_LAYER_HPP_
Relu_layer.cpp (src\caffe\layers):#include "caffe/layers/relu_layer.hpp"
Relu_layer.cpp (src\caffe\layers):void ReLULayer<Dtype>::Forward_cpu(const vector<Blob<Dtype>*>& bottom,
Relu_layer.cpp (src\caffe\layers):  Dtype negative_slope = this->layer_param_.relu_param().negative_slope();
Relu_layer.cpp (src\caffe\layers):void ReLULayer<Dtype>::Backward_cpu(const vector<Blob<Dtype>*>& top,
Relu_layer.cpp (src\caffe\layers):    Dtype negative_slope = this->layer_param_.relu_param().negative_slope();
Relu_layer.cpp (src\caffe\layers):STUB_GPU(ReLULayer);
Relu_layer.cpp (src\caffe\layers):INSTANTIATE_CLASS(ReLULayer);
Relu_layer.hpp (include\caffe\layers):#ifndef CAFFE_RELU_LAYER_HPP_
Relu_layer.hpp (include\caffe\layers):#define CAFFE_RELU_LAYER_HPP_
Relu_layer.hpp (include\caffe\layers):class ReLULayer : public NeuronLayer<Dtype> {
Relu_layer.hpp (include\caffe\layers):   * @param param provides ReLUParameter relu_param,
Relu_layer.hpp (include\caffe\layers):   *     with ReLULayer options:
Relu_layer.hpp (include\caffe\layers):  explicit ReLULayer(const LayerParameter& param)
Relu_layer.hpp (include\caffe\layers):  virtual inline const char* type() const { return "ReLU"; }
Relu_layer.hpp (include\caffe\layers):   * @brief Computes the error gradient w.r.t. the ReLU inputs.
Relu_layer.hpp (include\caffe\layers):#endif  // CAFFE_RELU_LAYER_HPP_
Sigmoid_layer.hpp (include\caffe\layers): * The ReLULayer is often a better choice for this reason.
Tanh_layer.cpp (src\caffe\layers):// Adapted from ReLU layer code written by Yangqing Jia
Tanh_layer.hpp (include\caffe\layers): * The ReLULayer is often a better choice for this reason.
Test_net.cpp (src\caffe\test):        "  name: 'relu1' "
Test_net.cpp (src\caffe\test):        "  type: 'ReLU' "
Test_neuron_layer.cpp (src\caffe\test):#include "caffe/layers/prelu_layer.hpp"
Test_neuron_layer.cpp (src\caffe\test):#include "caffe/layers/relu_layer.hpp"
Test_neuron_layer.cpp (src\caffe\test):#include "caffe/layers/cudnn_relu_layer.hpp"
Test_neuron_layer.cpp (src\caffe\test):  void TestPReLU(PReLULayer<Dtype> *layer) {
Test_neuron_layer.cpp (src\caffe\test):    bool channel_shared = layer->layer_param().prelu_param().channel_shared();
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestReLU) {
Test_neuron_layer.cpp (src\caffe\test):  ReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestReLUGradient) {
Test_neuron_layer.cpp (src\caffe\test):  ReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestReLUWithNegativeSlope) {
Test_neuron_layer.cpp (src\caffe\test):      "relu_param { negative_slope: 0.01 }", &layer_param));
Test_neuron_layer.cpp (src\caffe\test):  ReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestReLUGradientWithNegativeSlope) {
Test_neuron_layer.cpp (src\caffe\test):      "relu_param { negative_slope: 0.01 }", &layer_param));
Test_neuron_layer.cpp (src\caffe\test):  ReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestELUasReLU) {
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestELUasReLUGradient) {
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUParam) {
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUForward) {
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):  this->TestPReLU(&layer);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUForwardChannelShared) {
Test_neuron_layer.cpp (src\caffe\test):  layer_param.mutable_prelu_param()->set_channel_shared(true);
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):  this->TestPReLU(&layer);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUGradient) {
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUGradientChannelShared) {
Test_neuron_layer.cpp (src\caffe\test):  layer_param.mutable_prelu_param()->set_channel_shared(true);
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUConsistencyReLU) {
Test_neuron_layer.cpp (src\caffe\test):  LayerParameter prelu_layer_param;
Test_neuron_layer.cpp (src\caffe\test):  LayerParameter relu_layer_param;
Test_neuron_layer.cpp (src\caffe\test):  relu_layer_param.mutable_relu_param()->set_negative_slope(0.25);
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> prelu(prelu_layer_param);
Test_neuron_layer.cpp (src\caffe\test):  ReLULayer<Dtype> relu(relu_layer_param);
Test_neuron_layer.cpp (src\caffe\test):  prelu.SetUp(this->blob_bottom_vec_, this->blob_top_vec_);
Test_neuron_layer.cpp (src\caffe\test):  relu.SetUp(blob_bottom_vec_2, blob_top_vec_2);
Test_neuron_layer.cpp (src\caffe\test):  prelu.Forward(this->blob_bottom_vec_, this->blob_top_vec_);
Test_neuron_layer.cpp (src\caffe\test):  relu.Forward(this->blob_bottom_vec_, blob_top_vec_2);
Test_neuron_layer.cpp (src\caffe\test):  prelu.Backward(this->blob_top_vec_, propagate_down, this->blob_bottom_vec_);
Test_neuron_layer.cpp (src\caffe\test):  relu.Backward(blob_top_vec_2, propagate_down, blob_bottom_vec_2);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(NeuronLayerTest, TestPReLUInPlace) {
Test_neuron_layer.cpp (src\caffe\test):  LayerParameter prelu_layer_param;
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> prelu(prelu_layer_param);
Test_neuron_layer.cpp (src\caffe\test):  PReLULayer<Dtype> prelu2(prelu_layer_param);
Test_neuron_layer.cpp (src\caffe\test):  prelu.SetUp(this->blob_top_vec_, this->blob_top_vec_);
Test_neuron_layer.cpp (src\caffe\test):  prelu2.SetUp(blob_middle_vec_2, blob_top_vec_2);
Test_neuron_layer.cpp (src\caffe\test):  prelu.Forward(this->blob_top_vec_, this->blob_top_vec_);
Test_neuron_layer.cpp (src\caffe\test):  prelu2.Forward(blob_middle_vec_2, blob_top_vec_2);
Test_neuron_layer.cpp (src\caffe\test):  prelu.Backward(this->blob_top_vec_, propagate_down, this->blob_top_vec_);
Test_neuron_layer.cpp (src\caffe\test):  prelu2.Backward(blob_top_vec_2, propagate_down, blob_middle_vec_2);
Test_neuron_layer.cpp (src\caffe\test):  for (int s = 0; s < prelu.blobs()[0]->count(); ++s) {
Test_neuron_layer.cpp (src\caffe\test):    EXPECT_EQ(prelu.blobs()[0]->cpu_diff()[s],
Test_neuron_layer.cpp (src\caffe\test):        prelu2.blobs()[0]->cpu_diff()[s]);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(CuDNNNeuronLayerTest, TestReLUCuDNN) {
Test_neuron_layer.cpp (src\caffe\test):  CuDNNReLULayer<TypeParam> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(CuDNNNeuronLayerTest, TestReLUGradientCuDNN) {
Test_neuron_layer.cpp (src\caffe\test):  CuDNNReLULayer<TypeParam> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(CuDNNNeuronLayerTest, TestReLUWithNegativeSlopeCuDNN) {
Test_neuron_layer.cpp (src\caffe\test):      "relu_param { negative_slope: 0.01 }", &layer_param));
Test_neuron_layer.cpp (src\caffe\test):  CuDNNReLULayer<TypeParam> layer(layer_param);
Test_neuron_layer.cpp (src\caffe\test):TYPED_TEST(CuDNNNeuronLayerTest, TestReLUGradientWithNegativeSlopeCuDNN) {
Test_neuron_layer.cpp (src\caffe\test):      "relu_param { negative_slope: 0.01 }", &layer_param));
Test_neuron_layer.cpp (src\caffe\test):  CuDNNReLULayer<TypeParam> layer(layer_param);
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu1' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu2' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu3' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu4' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu5' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu6' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu7' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu1' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'relu1' "
Test_split_layer.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_split_layer.cpp (src\caffe\test):      "  name: 'innerprod1_relu1_0_split' "
Test_split_layer.cpp (src\caffe\test):      "  top: 'innerprod1_relu1_0_split_0' "
Test_split_layer.cpp (src\caffe\test):      "  top: 'innerprod1_relu1_0_split_1' "
Test_split_layer.cpp (src\caffe\test):      "  bottom: 'innerprod1_relu1_0_split_0' "
Test_split_layer.cpp (src\caffe\test):      "  bottom: 'innerprod1_relu1_0_split_1' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu1' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu2' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu3' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu4' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu5' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu7' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu1' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu2' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu3' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu4' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu5' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu7' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu1' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu2' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu3' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu4' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu5' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "    name: 'relu7' "
Test_upgrade_proto.cpp (src\caffe\test):      "    type: 'relu' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu1' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu2' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu3' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu4' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu5' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu7' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: RELU "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu1' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu2' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu3' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu4' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu5' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu6' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Test_upgrade_proto.cpp (src\caffe\test):      "  name: 'relu7' "
Test_upgrade_proto.cpp (src\caffe\test):      "  type: 'ReLU' "
Upgrade_proto.cpp (src\caffe\util):  } else if (type == "relu") {
Upgrade_proto.cpp (src\caffe\util):    return V1LayerParameter_LayerType_RELU;
Upgrade_proto.cpp (src\caffe\util):  if (v1_layer_param.has_relu_param()) {
Upgrade_proto.cpp (src\caffe\util):    layer_param->mutable_relu_param()->CopyFrom(
Upgrade_proto.cpp (src\caffe\util):        v1_layer_param.relu_param());
Upgrade_proto.cpp (src\caffe\util):  case V1LayerParameter_LayerType_RELU:
Upgrade_proto.cpp (src\caffe\util):    return "ReLU";
